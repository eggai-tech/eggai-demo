name: eggai-examples
networks:
  eggai-example-network:
    driver: bridge
volumes:
  redpanda: null
  postgres_temporal_data: null
  postgres_mlflow_data: null
  vespa-node0-data: null
  vespa-node1-data: null
  vespa-node2-data: null
services:
  redpanda:
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
      - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      - --rpc-addr redpanda:33145
      - --advertise-rpc-addr redpanda:33145
      - --mode dev-container
      - --smp 1
      - --default-log-level=info
    image: docker.redpanda.com/redpandadata/redpanda:v24.3.1
    container_name: redpanda
    volumes:
      - redpanda:/var/lib/redpanda/data
    networks:
      - eggai-example-network
    ports:
      - 18081:18081
      - 18082:18082
      - 19092:19092
      - 19644:9644
    healthcheck:
      test: ["CMD", "rpk", "cluster", "info", "--brokers=redpanda:9092"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s
  console:
    container_name: redpanda-console
    image: docker.redpanda.com/redpandadata/console:v2.8.0
    networks:
      - eggai-example-network
    entrypoint: /bin/sh
    command: -c 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml; /app/console -config.filepath=${CONFIG_FILEPATH:-/tmp/config.yml}'
    environment:
      CONFIG_FILEPATH: ${CONFIG_FILEPATH:-/tmp/config.yml}
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda:9092"]
          schemaRegistry:
            enabled: true
            urls: ["http://redpanda:8081"]
        redpanda:
          adminApi:
            enabled: true
            urls: ["http://redpanda:9644"]
    ports:
      - 8082:8080
    depends_on:
      redpanda:
        condition: service_healthy
  topic-init:
    image: docker.redpanda.com/redpandadata/redpanda:v24.3.1
    container_name: topic-init
    networks:
      - eggai-example-network
    depends_on:
      redpanda:
        condition: service_healthy
    entrypoint: /bin/sh
    command: -c "
      echo 'Waiting for Redpanda cluster to be ready...' &&
      sleep 5 &&
      rpk topic create human --brokers=redpanda:9092 &&
      echo 'Topic humans created successfully!'" &&
      rpk topic create agents --brokers=redpanda:9092 &&
      echo 'Topic agents created successfully!'"
  otel-collector:
    container_name: otel-collector
    image: otel/opentelemetry-collector:0.86.0
    command: [ "--config=/etc/otel-collector.yaml" ]
    volumes:
      - ./dockerConfig/otel-collector.yaml:/etc/otel-collector.yaml
    ports:
      - "4318:4318"
    networks:
      - eggai-example-network
  tempo:
    container_name: tempo
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./dockerConfig/tempo.yaml:/etc/tempo.yaml
      - ./temp/tempo-data:/tmp/tempo
    ports:
      - "14268:14268"
      - "3200"
      - "4317:4317"
      - "9411:9411"
      - "16686"
    networks:
      - eggai-example-network
  prometheus:
    container_name: prometheus
    image: prom/prometheus:latest
    command:
      - --config.file=/etc/prometheus.yaml
      - --web.enable-remote-write-receiver
      - --enable-feature=exemplar-storage
      - --enable-feature=native-histograms
    volumes:
      - ./dockerConfig/prometheus.yaml:/etc/prometheus.yaml
    ports:
      - "9090:9090"
    networks:
      - eggai-example-network
  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    volumes:
      - ./dockerConfig/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      - ./dockerConfig/grafana-dashboard.json:/var/lib/grafana/dashboards/grafana-dashboard.json
      - ./dockerConfig/grafana-provisioning.yaml:/etc/grafana/provisioning/dashboards/dashboard.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    ports:
      - "3000:3000"
    networks:
      - eggai-example-network
  minio-setup:
    container_name: minio-setup
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: [ "/bin/sh", "-c", "sleep 5 && mc alias set minio http://minio:9000 user password && mc mb -p minio/mlflow && mc anonymous set download minio/mlflow && echo 'MinIO bucket setup completed successfully'" ]
    networks:
      - eggai-example-network
  minio:
    container_name: minio
    image: minio/minio
    expose:
      - "9000"
    ports:
      - "9000:9000"
      # MinIO Console is available at http://localhost:9001
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: "user"
      MINIO_ROOT_PASSWORD: "password"
    command: server /data --console-address ":9001"
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    networks:
      - eggai-example-network
  mlflow-artifacts-server:
    container_name: mlflow-artifacts-server
    image: ghcr.io/mlflow/mlflow:v3.0.0rc2
    depends_on:
      - minio
      - minio-setup
    expose:
      - "5500"
    ports:
      - "5500:5500"
    environment:
      # MinIO credentials
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: "user"
      AWS_SECRET_ACCESS_KEY: "password"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5500
      --artifacts-destination s3://mlflow
      --gunicorn-opts "--log-level debug"
      --artifacts-only
    networks:
      - eggai-example-network
  postgres-temporal:
    container_name: postgres-temporal
    image: postgres
    environment:
      POSTGRES_DB: temporal
      POSTGRES_USER: temporal
      POSTGRES_PASSWORD: temporal
    ports:
      - "5433:5432"
    volumes:
      - postgres_temporal_data:/var/lib/postgresql/data
    networks:
      - eggai-example-network
    healthcheck:
      test:
        ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB} -t 1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 10s
  postgres-mlflow:
    container_name: postgres-mlflow
    image: postgres
    environment:
      POSTGRES_DB: db
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_mlflow_data:/var/lib/postgresql/data
    networks:
      - eggai-example-network
    healthcheck:
      test:
        ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB} -t 1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 10s
  temporal:
    container_name: temporal
    depends_on:
      postgres-temporal:
        condition: service_healthy
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=postgres-temporal
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
    image: temporalio/auto-setup:1.23.0
    networks:
      - eggai-example-network
    ports:
      - 7233:7233
    volumes:
      - ./dockerConfig/development-sql.yaml:/etc/temporal/config/dynamicconfig/development-sql.yaml
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7233/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
  temporal-ui:
    container_name: temporal-ui
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    image: temporalio/ui:2.26.2
    networks:
      - eggai-example-network
    ports:
      - 8081:8080
  mlflow-tracking-server:
    container_name: mlflow-tracking-server
    image: ghcr.io/mlflow/mlflow:v3.0.0rc2
    depends_on:
      - postgres-mlflow
      - mlflow-artifacts-server
    expose:
      - "5001"
    ports:
      # MLflow UI is available at http://localhost:5001
      - "5001:5001"
    environment:
      # For external client connections
      MLFLOW_ARTIFACT_ROOT: http://localhost:5500/api/2.0/mlflow-artifacts/artifacts
      # Direct S3 access to MinIO
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: "user"
      AWS_SECRET_ACCESS_KEY: "password"
    command: >
      bash -c "pip install psycopg2-binary boto3 && mlflow server
      --host 0.0.0.0
      --port 5001
      --backend-store-uri postgresql://user:password@postgres-mlflow:5432/db
      --default-artifact-root s3://mlflow
      --gunicorn-opts '--log-level debug'"
    networks:
      - eggai-example-network
  # Vespa Node 0 (Config Server + Services)
  vespa-node-0:
    image: vespaengine/vespa
    container_name: vespa-node-0
    hostname: vespa-node-0.eggai-example-network
    networks:
      - eggai-example-network
    environment:
      - VESPA_CONFIGSERVERS=vespa-node-0.eggai-example-network,vespa-node-1.eggai-example-network,vespa-node-2.eggai-example-network
    ports:
      - "8080:8080"
      - "19071:19071"
      - "19050:19050"
      - "19100:19100"
    volumes:
      - vespa-node0-data:/opt/vespa/var
    command: configserver,services
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:19071/state/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Vespa Node 1 (Config Server + Services)
  vespa-node-1:
    image: vespaengine/vespa
    container_name: vespa-node-1
    hostname: vespa-node-1.eggai-example-network
    networks:
      - eggai-example-network
    environment:
      - VESPA_CONFIGSERVERS=vespa-node-0.eggai-example-network,vespa-node-1.eggai-example-network,vespa-node-2.eggai-example-network
    ports:
      - "8083:8080"
      - "19072:19071"
      - "19101:19100"
    volumes:
      - vespa-node1-data:/opt/vespa/var
    command: configserver,services
    depends_on:
      - vespa-node-0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:19071/state/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # Vespa Node 2 (Config Server + Services)
  vespa-node-2:
    image: vespaengine/vespa
    container_name: vespa-node-2
    hostname: vespa-node-2.eggai-example-network
    networks:
      - eggai-example-network
    environment:
      - VESPA_CONFIGSERVERS=vespa-node-0.eggai-example-network,vespa-node-1.eggai-example-network,vespa-node-2.eggai-example-network
    ports:
      - "8084:8080"
      - "19073:19071"
      - "19102:19100"
    volumes:
      - vespa-node2-data:/opt/vespa/var
    command: configserver,services
    depends_on:
      - vespa-node-0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:19071/state/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s


